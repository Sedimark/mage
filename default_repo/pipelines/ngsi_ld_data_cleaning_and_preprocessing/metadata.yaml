blocks:
- all_upstream_blocks_executed: true
  color: null
  configuration:
    end_time: '{"type": "date", "description": "The stop date of the time interval.",
      "format": "YYYY-MM-DDThh:mm:ssZ"}'
    entity_id: '{"type": "drop_down", "description": "This is the ID of the entity
      that is stored in the NGSI-LD Broker", "values": ["urn:ngsi-ld:Sedimark:CrowdFlowObserved:100016667"]}'
    start_time: '{"type": "date", "description": "The start date of the time interval.",
      "format": YYYY-MM-DDThh:mm:ssZ"}'
  downstream_blocks:
  - handle_missing_values_1
  executor_config: null
  executor_type: local_python
  has_callback: false
  language: python
  name: ngsild_temporal_data_retrieval_2
  retry_config: null
  status: updated
  timeout: null
  type: data_loader
  upstream_blocks: []
  uuid: ngsild_temporal_data_retrieval_2
- all_upstream_blocks_executed: false
  color: null
  configuration:
    columns: '{"type": "text", "description": "The list columns to apply the strategy
      on. If empty, all columns will be considered. e.g. [\"column1\", \"column2\"]"}'
    drop_threshold_col: '{"type": "number", "description": "The threshold for dropping
      columns based on the percentage of missing values. If the percentage of missing
      values in a column exceeds this threshold, the column will be dropped. The value
      should be between 0 and 1. Default is 0.5"}'
    file_source:
      path: transformers/handle_missing_values_1.py
    impute_value: '{"type": "number", "description": "The value to use for imputation
      when the strategy is set to `impute_constant`. If empty, the default value 0
      will be used."}'
    strategy: '{"type": "drop_down", "description": "The strategy to handle missing
      values.", "values": ["default_imputation", "drop_rows", "drop_cols", "impute_mean",
      "impute_median", "impute_mode", "impute_constant"]}'
  downstream_blocks:
  - correct_data_types_1
  executor_config: null
  executor_type: local_python
  has_callback: false
  language: python
  name: handle_missing_values_1
  retry_config: null
  status: not_executed
  timeout: null
  type: transformer
  upstream_blocks:
  - ngsild_temporal_data_retrieval_2
  uuid: handle_missing_values_1
- all_upstream_blocks_executed: false
  color: null
  configuration:
    file_source:
      date_time_format: '{"type": "text", "description": "The date time format to
        use for parsing date time columns. e.g. %Y-%m-%dT%H:%M:%S"}'
      path: transformers/correct_data_types_1.py
      type_conversions: '{"type": "text", "description": "A dictionary of type conversions
        to apply to the columns. e.g. {\"column1\": \"int\", \"column2\": \"float\"}"}'
  downstream_blocks:
  - remove_duplicates_1
  executor_config: null
  executor_type: local_python
  has_callback: false
  language: python
  name: correct_data_types_1
  retry_config: null
  status: not_executed
  timeout: null
  type: transformer
  upstream_blocks:
  - handle_missing_values_1
  uuid: correct_data_types_1
- all_upstream_blocks_executed: false
  color: null
  configuration:
    file_source:
      path: transformers/remove_duplicates_1.py
    keep: '{"type": "drop_down", "description": "The strategy to use for keeping duplicates.
      Options are `first`, `last`, or False. If set to False, all duplicates will
      be removed.", "values": ["first", "last", False]}'
    subset: '{"type": "text", "description": "The list of columns to consider for
      identifying duplicates. If empty, all columns will be considered. e.g. [\"column1\",
      \"column2\"]"}'
  downstream_blocks:
  - rename_columns_1
  executor_config: null
  executor_type: local_python
  has_callback: false
  language: python
  name: remove_duplicates_1
  retry_config: null
  status: not_executed
  timeout: null
  type: transformer
  upstream_blocks:
  - correct_data_types_1
  uuid: remove_duplicates_1
- all_upstream_blocks_executed: false
  color: null
  configuration:
    drop_columns: '{"type": "text", "description": "A list of columns to drop. If
      empty, no columns will be dropped. e.g. [\"column1\", \"column2\"]"}'
    file_source:
      path: transformers/rename_columns_1.py
    rename_map: '{"type": "text", "description": "A dictionary mapping old column
      names to new column names. e.g. {\"old_name1\": \"new_name1\", \"old_name2\":
      \"new_name2\"}"}'
  downstream_blocks: []
  executor_config: null
  executor_type: local_python
  has_callback: false
  language: python
  name: rename_columns_1
  retry_config: null
  status: not_executed
  timeout: null
  type: transformer
  upstream_blocks:
  - remove_duplicates_1
  uuid: rename_columns_1
cache_block_output_in_memory: false
callbacks: []
concurrency_config: {}
conditionals: []
created_at: '2025-06-16 13:34:05.133412+00:00'
data_integration: null
description: This pipeline retrieves temporal data from an NGSI-LD Broker, handles
  missing values, corrects data types, removes duplicates, and renames columns.
executor_config: {}
executor_count: 1
executor_type: null
extensions: {}
name: ngsi_ld_data_cleaning_and_preprocessing
notification_config: {}
remote_variables_dir: null
retry_config: {}
run_pipeline_in_one_process: false
settings:
  triggers: null
spark_config: {}
tags:
- data_preprocessing
type: python
uuid: ngsi_ld_data_cleaning_and_preprocessing
variables_dir: /home/src/mage_data/default_repo
widgets: []
